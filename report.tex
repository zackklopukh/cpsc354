\documentclass{article}

\usepackage{tikz} 
\usetikzlibrary{automata, positioning, arrows} 

\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{color}
\usepackage{parskip}
\usepackage{hyperref}
  \hypersetup{
    colorlinks = true,
    urlcolor = blue,       % color of external links using \href
    linkcolor= blue,       % color of internal links 
    citecolor= blue,       % color of links to bibliography
    filecolor= blue,        % color of file links
    }
    
\usepackage{listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=haskell,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\newtheoremstyle{theorem}
  {\topsep}   % ABOVESPACE
  {\topsep}   % BELOWSPACE
  {\itshape\/}  % BODYFONT
  {0pt}       % INDENT (empty value is the same as 0pt)
  {\bfseries} % HEADFONT
  {.}         % HEADPUNCT
  {5pt plus 1pt minus 1pt} % HEADSPACE
  {}          % CUSTOM-HEAD-SPEC
\theoremstyle{theorem} 
   \newtheorem{theorem}{Theorem}[section]
   \newtheorem{corollary}[theorem]{Corollary}
   \newtheorem{lemma}[theorem]{Lemma}
   \newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
   \newtheorem{definition}[theorem]{Definition}
   \newtheorem{example}[theorem]{Example}
\theoremstyle{remark}    
  \newtheorem{remark}[theorem]{Remark}

% Set up the listing environment for Lean code
\lstset{
  language=lean,
  basicstyle=\ttfamily,
  breaklines=true,
  frame=single,
  captionpos=b
}

\title{CPSC-354 Report}
\author{Zack Klopukh \\ Chapman University}

\date{\today} 

\begin{document}

\maketitle

\begin{abstract}
Documentation of my notes, questions, and homework throughout my CPSC-354 class can be found here.
\setcounter{tocdepth}{3}
\tableofcontents

\section{Introduction}\label{intro}

\section{Week by Week}\label{homework}

\subsection{Week 1}

\subsubsection*{Notes}

Using proofs is important for reasoning on how computers can operate.

\subsubsection*{Homework}

5) Goal: $a+(b+0)+(c+0)=a+b+c$

 \verb{rw [add_zero b, add_zero c]
\\
$a+b+c=a+b+c$ \\
rfl
\\
\verb{ Here we use  add_zero to rewrite and remove the extra zeros so that both sides are equal by reflexivity.
\\ \\
6) Goal: $a+(b+0)+(c+0)=a+b+c$

 \verb{rw [add_zero b, add_zero c]
 \\
 $a+b+c=a+b+c$ \\
 rfl
A nearly identical solution as number 5. \\

7) Goal: $succ n = succ(n+0)$
\verb{ rw [add_zero]
\\
rfl \\
\verb{ Here we used add_zero to rewrite n+0 to n which was all it took to show equality through reflexivity.
\\ \\
8) Goal: $2+2=4$ \\
\verb { rw [four_eq_succ_three]
\\
2 + 2 = succ 3 \\
\verb. rw [three_eq_succ_two]
\\
2 + 2 = succ (succ 2) \\
\verb. rw [two_eq_succ_one]
\\
succ 1 + succ 1 = succ (succ (succ 1)) \\
\verb/ rw [one_eq_succ_zero]
\\ succ (succ 0) + succ (succ 0) = succ (succ (succ (succ 0))) \\
\verb/ rw [add_succ]
\\ succ (succ (succ 0) + succ 0) = succ (succ (succ (succ 0))) \\
\verb / rw [add_succ]
\\ succ (succ (succ (succ 0) + 0)) = succ (succ (succ (succ 0))) \\
\verb/ rw [add_zero]
\\ succ (succ (succ (succ 0))) = succ (succ (succ (succ 0)))
\\
\verb / rfl
\\
This is the longest proof in the homework and involves multiple rewrittings to show. The process I took was turning both 2's and the 4 into their forms as successors of 0. From that point I added successors to the left side and by doing so I rewrite the two separate 2's into one large successor. Finally by using add zero, I removed one of the two left terms completely making it a single term on the left and right, both representative of 4.



% Make sure that this section can be read without referring back to the homework question. Introduce the question/problem and repeat it in your own words. Make sure to typset your homework in a way that makes it clear what  the question and what the answer is. Present it as a worked example would be presented in a textbook. 

% Also explain what you learn from the homework. Each homework was carefully drafted to bring home a particular teaching point. Make sure to explain what this point is. Relate it to the big questions mentioned above. 

%In case you want to draw automata in Latex, you can use the tikz %package. Here is an example of a simple automaton:
%
%\begin{tikzpicture}[shorten >=1pt,node distance=2cm,on grid,auto] 
%  \node[state] (q_1)   {$q_1$}; 
%  \node[state] (q_2) [above right=of q_1] {$q_2$}; 
%  \node[state] (q_3) [below right=of q_2] {$q_3$}; 
%   \path[->] 
%   (q_1) edge  node {0} (q_2)
%         edge  node [swap] {1} (q_3)
%   (q_2) edge  node  {1} (q_3)
%         edge [loop above] node {0} ()
%   (q_3) edge [loop below] node {0,1} ();
%\end{tikzpicture}
%
%By the way, GPT-4 is quite good at outputting tikz code.

\subsubsection*{Comments and Questions}

This introduction world taught me how precise proofs need to be. I am beginning to understand how important it is to a machine that proofs are completely concrete, to the point where 2+2=4 becomes a tricky problem. As I go on to take these rewrites for granted, I will with the understanding that under the hood the computer does not go off intuition, but precise and exact steps. \\\\
 Question of the week:
How can systems of algorithmic reasoning as shown in the tutorial world, based in discrete mathematics, be encoded in modern programming languages?
%I expect you to read the lecture notes. 

\subsection{Week 2}


\subsubsection*{Homework}

\textbf{Question 1:} Prove the theorem `zero\_add`: For all natural numbers \( n \), we have \( 0 + n = n \).

\textbf{Proof:}
\begin{verbatim}
theorem zero_add : ∀ n : ℕ, 0 + n = n :=

  intro n,
  induction n with d hd,
  rw add_zero
  rw add_succ
  rw hd
  rfl

This uses induction to prove the zero_add property. It is a simple way to introduce inductive reasoning.
\end{verbatim}

\textbf{Question 2:} Prove the theorem: For all natural numbers \( a, b \), we have \( \text{succ}(a) + b = \text{succ}(a + b) \).

\textbf{Proof:}
\begin{verbatim}
induction b with a b
rw [add_zero]
rw [add_zero]
rfl
rw [add_succ]
rw [b]
rw [add_succ]
rfl
\end{verbatim}
\end{verbatim}

This proof uses induction on \( b \) to show that adding \( \text{succ}(a) \) to \( b \) results in \( \text{succ}(a + b) \). Inductive reasoning is key to establishing this property.
\end{verbatim}

\textbf{Question 3:} Prove the theorem: On the set of natural numbers, addition is commutative. In other words, if \( a \) and \( b \) are arbitrary natural numbers, then \( a + b = b + a \).

\textbf{Proof:}
\begin{verbatim}
induction a with b hd
rw [add_zero]
rw [zero_add]
rfl
rw [add_succ]
rw [succ_add]
rw [succ_eq_add_one]
rw [succ_eq_add_one]
rw [hd]
rfl
\end{verbatim}

This proof establishes the commutativity of addition on natural numbers by using induction on \( a \). Each step involves rewrites that simplify the equation until both sides match.

\textbf{Question 4:} Prove the theorem: On the set of natural numbers, addition is associative. In other words, if \( a \), \( b \), and \( c \) are arbitrary natural numbers, we have \( (a + b) + c = a + (b + c) \).

\textbf{Proof:}
\begin{verbatim}
induction a with b hd
rw [zero_add]
rw [add_comm]
rw [zero_add]
rfl
rw [succ_add]
rw [succ_add]
rw [succ_add]
rw [succ_eq_add_one]
rw [succ_eq_add_one]
rw [hd]
rfl
\end{verbatim}

This proof uses induction on \( a \) to establish the associativity of addition on the natural numbers. Each step simplifies the expression to demonstrate that the addition operation is associative.

\textbf{Question 5:} Prove the theorem: If \( a \), \( b \), and \( c \) are arbitrary natural numbers, we have \( (a + b) + c = (a + c) + b \).

\textbf{Proof:}
\begin{verbatim}
induction a with b hd
rw [zero_add]
rw [zero_add]
rw [add_comm]
rfl
rw [add_assoc]
nth_rewrite 1 [add_assoc]
nth_rewrite 2 [add_comm]
rfl
\end{verbatim}

This proof uses induction on \( a \) to show that the expression \( (a + b) + c \) can be rearranged to \( (a + c) + b \). Various rewrite steps and the commutativity and associativity of addition are used to achieve the result.


\subsubsection*{Comments and Questions}

In this homework, I used lean to complete many proofs I've done in Discrete Mathematics including commutativity and associativity. These are proofs that I did previously use induction to solve, but representing that through lean to a computer makes the challenge extra formal, as there can be no jumps in logic. It's another week where the homework makes me thoughtful on how computers function at a lower level. \\

What challenges or additional considerations might arise when using a more complicated set like the set of all real numbers compared to the set of natural numbers?

\subsection{Week 3}

\subsubsection*{Homework}


This week, I used a Large Language Model (LLM) to delve deeply into a research question that piqued my interest. Beyond obtaining basic answers, I further explored the advancements this topic has facilitated in various fields, as these developments are of particular interest to me.

What role does syntax play in the usability of programming languages? \\
For a comprehensive report detailing my research and findings, please refer to the following link: \\
\url{https://github.com/zackklopukh/LLMReport/blob/main/README.md}

\subsubsection*{Discord Posting}

In my literature review with GPT-4o, I examined the profound influence of user-friendly interfaces on programming languages. Initially, programming was confined to those with deep technical knowledge due to complex syntax and low-level languages. However, the evolution of programming syntax to more readable and high-level languages significantly broadened access to programming, inviting individuals from diverse fields to contribute and innovate. The shift from assembly languages to high-level languages such as FORTRAN, COBOL, and later Python and JavaScript revolutionized the field. This transition facilitated increased creativity and productivity, as developers could focus more on solving problems rather than managing low-level details. The development of high-level languages enabled rapid software development, democratizing programming and spurring advancements across various domains. In the report with GPT-4o, I explored how modern hybrid systems combine interpreted and compiled code to enhance performance and flexibility. Techniques like Just-In-Time (JIT) compilation and the integration of high-level languages with systems like WebAssembly illustrate the ongoing evolution of programming. These advancements reflect the growing synergy between user-friendly interfaces and robust performance, continuing to shape the future of programming.
\url{https://github.com/zackklopukh/LLMReport/blob/main/README.md}

\subsection{Week 4}

\subsubsection*{Homework}

\begin{figure} [H]
    \centering
    \includegraphics[width=0.5\linewidth]{Screenshot 2024-09-22 at 10.22.39 PM.png}
    \label{fig:enter-label}
\end{figure}
\begin{figure} [H]
    \centering
    \includegraphics[width=0.5\linewidth]{Screenshot 2024-09-22 at 10.23.10 PM.png}
    \label{fig:enter-label}
\end{figure}
\begin{figure} [H]
    \centering
    \includegraphics[width=0.5\linewidth]{Screenshot 2024-09-22 at 10.23.22 PM.png}
    \label{fig:enter-label}
\end{figure}
\begin{figure} [H]
    \centering
    \includegraphics[width=0.5\linewidth]{Screenshot 2024-09-22 at 10.23.36 PM.png}
    \label{fig:enter-label}
\end{figure}
\begin{figure} [H]
    \centering
    \includegraphics[width=0.5\linewidth]{Screenshot 2024-09-22 at 10.23.51 PM.png}
\label{fig:enter-label}
\end{figure}

\subsubsection*{Comments and Questions}

How do different parsing strategies compare when evaluating factors such as speed or memory usage?

Comparing a few different parsing strategies. Top-down recursive parsing may be slower if backtracking is required but it is very data efficient. Bottom-up can be faster especially for deterministic grammars although in some cases could use more memory in the case of more complex grammar. Packrat parsing is also very fast as it doesn't require any backtracking, but storing the intermediate results will require extra memory.

\subsection{Week 5}

\subsubsection*{Homework}

1. Exhibit evidence that you're planning a party.\\
\texttt{exact todo\_list}

2. Fill a box, label correctly.\\
\texttt{exact and\_intro p s}

3. Three x and\_intro.\\
\texttt{exact and\_intro (and\_intro a i) (and\_intro o u)}

4. Exhibit evidence that Pippin is coming to the party.\\
\texttt{exact and\_left vm}

5. Both P and Q entails just Q as well!\\
\texttt{exact h.right}

6. and\_intro, and\_left, and\_right.\\
\texttt{exact and\_intro (and\_left h1) (and\_right h2)}

7. Navigate the tree.\\
\texttt{exact h.left.left.right}

8. Take apart and build evidence.\\
\texttt{exact (h.left.right, h.right.right.left.left, h.left.left.left, h.left.left.right)}

\subsubsection*{Comments and Questions}

How do the conjunction and disjunction propositions seen in LLG influence the design of type systems in developed programming languages?

GPT: The conjunction (AND) and disjunction (OR) propositions from LLG significantly influence the design of type systems in programming languages by enabling type composition and enhancing type safety. Conjunctions correspond to product types (like tuples), allowing for complex data structures, while disjunctions relate to sum types (like variants), enabling flexible return types. These logical constructs facilitate pattern matching and support formal verification, ensuring that programs adhere to their specifications and reducing runtime errors. Overall, they provide a robust foundation for creating expressive and reliable type systems in modern programming languages.

\subsection{Week 6}

\subsubsection*{Homework}

1. Exhibit evidence that cake will be delivered to the party.\\
\texttt{exact bakery\_service p}

2. Cake is Cake.\\
\texttt{exact \lambda h : C \to h}

3. Show that \(^\) is commutative.\\
\texttt{exact \lambda h : I \land S \to \text{and\_intro}(h.right, h.left)}

4. Show that \(\to\) is transitive.\\
\texttt{exact \lambda h : c \to h2 (h1 h)}

5. Riffin is bringing a unicorn snack.\\
\texttt{exact h5 (h1 p)}

6. Conjunction interacting with implication.\\
\texttt{exact \lambda c : C \to \lambda d : D \to h (c,d)}

7. Conjunction interacting with interaction.\\
\texttt{exact \lambda c\_and\_d : C \land D \to h \, c\_and\_d.left \, c\_and\_d.right}

8. \(\to\) distributes over \(\land\).\\
\texttt{exact \lambda s : S \to (h.left s, h.right s)}

9. Write the necessary nested function(s)!\\
\texttt{exact \lambda r : R \, (\lambda s : S \to r, \lambda ns : -S \to r)}

\subsubsection*{Comments and Questions}

How do the conjunction and disjunction propositions seen in LLG influence the design of type systems in developed programming languages?

\subsection{Week 8-10}


\subsection*{Notes}
In recursive evaluations, like those in lambda calculus interpreters, it’s essential to grasp the recursive structure and how evaluation progresses through function calls and returns. When evaluating lambda expressions, each function call can trigger additional recursive calls to handle sub-expressions, such as applications or lambda abstractions, leading to deeper levels of recursion.

As the interpreter processes applications, it must evaluate both the function and its argument, further invoking the `evaluate()` function recursively. This descent continues until it reaches a terminal case, such as a variable or a fully reduced lambda expression. At that point, the interpreter starts returning from these calls, completing substitutions or reductions in the reverse order of invocation. 

This recursive pattern explains why the trace of calls typically shows increasing depth as recursion progresses and decreasing depth as the interpreter unwinds. Understanding this behavior is fundamental to comprehending the operational semantics of lambda calculus interpreters and similar recursive evaluation strategies in programming languages.
\subsubsection*{Homework}

\subsection*{Question 2}
We simplify the expression \( a \, b \, c \, d \) step-by-step and show how the left-associative function application works in lambda calculus.

This is interpreted as:
\[
a \, b \, c \, d = (((a \, b) \, c) \, d)
\]

\paragraph{Explanation:}
\begin{itemize}
    \item \textbf{Left-Associative Application:} Function application in lambda calculus is left-associative, meaning it groups from the left.
    \item \textbf{Step-by-Step Grouping:}
    \begin{align*}
        1. & \quad \text{Apply } a \text{ to } b: \quad (a \, b) \\
        2. & \quad \text{Then, apply the result to } c: \quad ((a \, b) \, c) \\
        3. & \quad \text{Finally, apply that result to } d: \quad (((a \, b) \, c) \, d)
    \end{align*}
\end{itemize}

Therefore, the original expression simplifies to:
\[
a \, b \, c \, d = (((a \, b) \, c) \, d)
\]

\subsection*{Question 3: Capture-Avoiding Substitution}
Capture-avoiding substitution is a method in lambda calculus for replacing variables in expressions while ensuring that no variable names are unintentionally "captured" by the scopes of bound variables. This technique preserves the intended variable bindings and avoids scope conflicts during substitution.

\paragraph{Explanation:}
A problem can occur when a bound variable in a lambda expression has the same name as a free variable in the term being substituted. To prevent this, a technique called "renaming" or "alpha-conversion" is used. This involves renaming bound variables to fresh, unique names before performing the substitution, ensuring that variable scopes remain distinct and no conflicts arise.

\subsection*{Question 4: Do all computations reduce to normal form?}
Not all lambda calculus expressions reduce to a normal form. While certain expressions, like those representing arithmetic operations or straightforward functions, eventually simplify to a fully evaluated state, others may result in non-termination, endlessly expanding without reaching a normal form.

\paragraph{Explanation:}
Expressions that fail to reduce to a normal form typically result from infinite loops or recursive definitions. A well-known example is the omega combinator, which undergoes infinite self-application, never achieving a normal form.

\subsection*{Question 5: The Smallest Lambda Expression That Does Not Reduce to Normal Form}
The omega combinator is the simplest lambda expression that does not reduce to a normal form. It effectively creates an infinite loop by repeatedly applying the function to itself, lacking a base case to halt the recursion.

\paragraph{Explanation:}
This minimal working example (MWE) demonstrates the problem of non-termination, where a lambda expression continues to expand indefinitely instead of simplifying. The omega combinator plays a key role in understanding recursion and non-termination within the theoretical framework of lambda calculus.

\subsection*{Question 7: Evaluating \( ((\lambda m. \lambda n. m \, n) \, (\lambda f. \lambda x. f \, (f \, x))) \, (\lambda f. \lambda x. f \, (f \, (f \, x))) \)}
1. Apply the first function \( \lambda m. \lambda n. m \, n \) to \( \lambda f. \lambda x. f \, (f \, x) \):
   \[
   (\lambda n.(\lambda f.\lambda x.f \, (f \, x)) \, n) \, (\lambda f.\lambda x.f \, (f \, (f \, x)))
   \]
2. Substitute \( n = \lambda f.\lambda x.f \, (f \, (f \, x)) \):
   \[
   (\lambda f.\lambda x.f \, (f \, x)) \, (\lambda f.\lambda x.f \, (f \, (f \, x)))
   \]
3. After substitutions and simplifications, the final result is:
   \[
   \lambda x. f \, (f \, (f \, x))
   \]

\subsection*{Question 8: Tracing Recursive Calls to \texttt{evaluate()} with \( ((\lambda m.\lambda n.m \, n) \, (\lambda f.\lambda x.f \, (f \, x))) \, (\lambda f.\lambda x.f \, x) \)}
Below is the trace, with line numbers and indentation representing the recursion depth:
\begin{verbatim}
12: eval (((\m.(\n.(m n))) (\f.(\x.(f (f x))))) (\f.(\x.(f x))))
    39: eval ((\m.(\n.(m n))) (\f.(\x.(f (f x)))))
        39: eval (\m.(\n.(m n)))
        39: eval (\f.(\x.(f (f x))))
    53: substitute (\n.(m n)) [m -> \f.\x.(f (f x))]
    12: eval (\n.(\f.\x.(f (f x)) n))
\end{verbatim}

\subsection*{Comments and Questions}
How does the use of functional representations in lambda calculus, such as Church numerals for encoding natural numbers, influence our understanding of data abstraction and manipulation in modern programming languages?


\subsection{Week 11}

  \subsubsection*{Homework}
  \textbf{Question:}

  For each of the possible combinations of the properties confluent (\( C \)), terminating (\( T \)), and having unique normal forms (\( UNF \)), determine whether such an ARS exists. Provide an example if possible, or explain why it cannot exist. For the examples, draw the ARS diagrams.

  \begin{center}
    \begin{tabular}{|c|c|c|l|}
      \hline
      Confluent (\( C \)) & Terminating (\( T \)) & Unique Normal Forms (\( UNF \)) & Example \\
      \hline
      True & True & True & Yes \\
      True & True & False & No \\
      True & False & True & Yes \\
      True & False & False & Yes \\
      False & True & True & No \\
      False & True & False & Yes \\
      False & False & True & No \\
      False & False & False & Yes \\
      \hline
    \end{tabular}
  \end{center}

  \textbf{Answer:}

  \textbf{1. Confluent, Terminating, and Unique Normal Forms: True}

  ARS with elements \( S = \{ a, b, c \} \) and reduction rules:

  \[
    a \to b, \quad b \to c
  \]

  \textit{Diagram:}

  \begin{center}
    \begin{tikzpicture}[node distance=2cm, ->, >=stealth, auto]
      \node (A) {\( a \)};
      \node (B) [right of=A] {\( b \)};
      \node (C) [right of=B] {\( c \)};
      \draw (A) to (B);
      \draw (B) to (C);
    \end{tikzpicture}
  \end{center}

  \textit{Analysis:}

Terminating | True, Reduction sequences eventually reach \( c \).
Confluent | True, No diverging reduction paths.
Unique Normal Forms | True, elements reduces to \( c \), the unique normal form.


  \textbf{2. Confluent and True, Unique Normal Forms False}

  This is \textbf{impossible}. In a confluent and terminating ARS, every element reduces to a unique normal form. Unique normal forms will be true.


  \textbf{3. Confluent and Unique Normal Forms True | Terminating False}

  \textit{Example:}

ARS with elements \( S = \{ a, b, c \} \) and rules:

  \[
    a \to b, \quad b \to a, \quad a \to c, \quad b \to c
  \]

  \textit{Diagram:}

  \begin{center}
    \begin{tikzpicture}[node distance=2cm, ->, >=stealth, auto]
      \node (A) {\( a \)};
      \node (B) [right of=A] {\( b \)};
      \node (C) [below of=A, node distance=1.5cm] {\( c \)};
      \draw (A) to (B);
      \draw (B) to (A);
      \draw (A) to (C);
      \draw (B) to (C);
    \end{tikzpicture}
  \end{center}

  \textit{Analysis:}

Terminating | False, Infinite loop between \( a \) and \( b \): \( a \to b \to a \to b \to \dots \)
Confluent | True. \( a \) and \( b \) reduce to \( c \), and any divergent paths converge.
Unique Normal Forms | True, All elements reduce to \( c \), the unique normal form.

  \textbf{4. Confluent True, Terminating and Unique Normal Forms False}

ARS with elements \( S = \{ a, b \} \) and rules:

  \[
    a \to b, \quad b \to a
  \]

  \textit{Diagram:}

  \begin{center}
    \begin{tikzpicture}[node distance=2cm, ->, >=stealth, auto]
      \node (A) {\( a \)};
      \node (B) [right of=A] {\( b \)};
      \draw (A) to (B);
      \draw (B) to (A);
    \end{tikzpicture}
  \end{center}

  \textit{Analysis:}

Terminating | False, Infinite loop between \( a \) and \( b \).
Confluent | True, No diverging paths. Reductions cycle between \( a \) and \( b \).
Unique Normal Forms | False, Neither \( a \) nor \( b \) is a normal form.

  \textbf{5. Confluent False, Terminating and Unique Normal Forms True}

  \textit{Explanation:}

  This combination is \textbf{impossible}. If an ARS has unique normal forms, it must be confluent.

  ---

  \textbf{6. Confluent and Unique Normal Forms False, Terminating True}

  Consider the ARS with elements \( S = \{ a, b, c \} \) and rules:

  \[
    a \to b, \quad a \to c
  \]

  \textit{Diagram:}

  \begin{center}
    \begin{tikzpicture}[->, >=stealth, auto]
      \node (A) at (0,0) {\( a \)};
      \node (B) at (2,1) {\( b \)};
      \node (C) at (2,-1) {\( c \)};
      \draw (A) to (B);
      \draw (A) to (C);
    \end{tikzpicture}
  \end{center}

Terminating | True, Reductions terminate at normal forms.
Confluent | False, From \( a \), can reach two different normal forms, \( b \) and \( c \), which aren't joinable.
Unique Normal Forms | false because The element \( a \) has two distinct normal forms.

  \textbf{7. Confluent and Terminating are False, Unique Normal Forms, True}


  Reasoning: Unique normal forms imply that the ARS is confluent and normalising.


  \textbf{8. Confluent, Terminating, and Unique Normal Forms are False}


  Example Consider the ARS with elements \( S = \{ a, b, c \} \) and rules:

  \[
    a \to b, \quad b \to a, \quad a \to c
  \]

  \textit{Diagram:}

  \begin{center}
    \begin{tikzpicture}[->, >=stealth, auto]
      \node (A) at (0,1) {\( a \)};
      \node (B) at (2,1) {\( b \)};
      \node (C) at (1,0) {\( c \)};
      \draw (A) to (B);
      \draw (B) to (A);
      \draw (A) to (C);
    \end{tikzpicture}
  \end{center}

  \textbf{Terminating:} No, infinite loop between \( a \) and \( b \).
  \textbf{Confluent:} No. either loop indefinitely between \( a \) and \( b \), or reduce to \( c \).
\textbf{Unique Normal Forms:} No, \( b \) and \( a \) do not reduce to \( c \) if we stay in the loop.

\subsection{Week 12}

\subsection*{Introduction}

This report analyzes several exercises on Abstract Reduction Systems (ARS). Each ARS consists of a set of words \( A \) (finite lists, strings) and a relation \( \to \) on \( A \). For each exercise, the task is to:
\begin{itemize}
    \item Show that the ARS is an algorithm (termination and unique results).
    \item Determine the specification the ARS implements.
    \item Characterize equivalence relations generated by the rewrite rules.
\end{itemize}
  \subsubsection*{Homework}
  \textbf{1. Rewrite Rule \( ba \to ab \)}

\textbf{Answer:}

The ARS terminates because each rewrite reduces the number of occurrences of the substring \( ba \). Once all \( ba \)'s are replaced with \( ab \)'s, no further rewrites can occur.

The normal form is a string where all \( a \)'s precede all \( b \)'s. For example, \( cbaad \to cabad \to caabd \).

The ARS is confluent because any sequence of rewrites results in the same normal form, where all \( a \)'s appear before \( b \)'s.

The algorithm implements sorting all \( a \)'s before \( b \)'s in any string.

\textbf{2. Rewrite Rules}

Given the rewrite rules:
\[
\begin{aligned}
    aa &\to a \\
    bb &\to a \\
    ab &\to b \\
    ba &\to b
\end{aligned}
\]

\textbf{Question:}

Why does the ARS terminate? What are the normal forms? Is there a string \( s \) that reduces to both \( a \) and \( b \)? Show that the ARS is confluent. Describe the equality relation generated by the rewrite rules.

\textbf{Answer:}

The ARS terminates because each rewrite either reduces the string's length or does not increase it. This guarantees that no infinite rewriting sequence exists.

The possible normal forms are \( a \) and \( b \).

Yes, there exist strings that reduce to both \( a \) and \( b \), for example, \( s = aabb \), depending on the rewrite order.

The ARS is not confluent since different rewrite sequences may lead to different normal forms. For confluence, additional rules or constraints are required.

The equality relation \( = \) is determined by counting the occurrences of \( a \)'s and \( b \)'s. Modular arithmetic can describe equivalence: strings with the same parity of \( a \)'s and \( b \)'s are equivalent.

\textbf{3. Rewrite Rules}

Given the rewrite rules:
\[
\begin{aligned}
    aa &\to a \\
    bb &\to b \\
    ba &\to ab \\
    ab &\to ba
\end{aligned}
\]

\textbf{Question:}

Why does the ARS not terminate? What are the normal forms? Modify the ARS to make it terminating, with unique normal forms. Describe the specification implemented by the ARS.

\textbf{Answer:}

The ARS does not terminate due to the cycling behavior between \( ab \) and \( ba \).

Without termination, there are no guaranteed normal forms.

To ensure termination, modify the rules to prioritize a specific order, such as enforcing \( ba \to ab \) and disallowing cycles.

The ARS relates to parity-based transformations, ensuring consistent ordering based on equivalence classes.

\textbf{5. Rewrite Rules}

Given the rewrite rules:
\[
\begin{aligned}
    ab &\to ba \\
    ba &\to ab \\
    aa &\to \epsilon \\
    b &\to \epsilon
\end{aligned}
\]

\textbf{Question:}

Why does the ARS not terminate? How many equivalence classes does \( \leftrightarrow^* \) have? What are the normal forms? Can you change the rules to make the ARS terminating without changing its equivalence classes?

\textbf{Answer:}

The ARS does not terminate due to cyclic rewrites between \( ab \) and \( ba \).

The system has two equivalence classes, which can be characterized by whether the string length is even or odd after applying reductions.

To make the ARS terminating, modify the rule \( aa \to \epsilon \) to \( aa \to a \) and restrict cycling behavior.
\subsection*{Comments and Questions}
How can we systematically determine whether a given set of rewrite rules leads to an infinite sequence of rewrites, especially when dealing with large alphabets or complex rules?
\subsection{\ldots}

\ldots

\section{Lessons from the Assignments}

Write this section during the semester. This is approximately a quarter of apage per week and the material should come from the work you do anyway. Just keep your eyes open for interesting lessons.

Make sure that you use \LaTeX{} to structure your writing (eg by using subsections).

\section{Conclusion}\label{conclusion}

Soon to be.

\begin{thebibliography}{99}
\bibitem[BLA]{bla} Author, \href{https://en.wikipedia.org/wiki/LaTeX}{Title}, Publisher, Year.
\end{thebibliography}

\end{document}